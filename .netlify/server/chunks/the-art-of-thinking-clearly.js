import { c as create_ssr_component } from './index3.js';
const metadata = {
	title: 'The Art of Thinking Clearly',
	date: '2022-11-26',
	categories: ['psychology']
};
const The_art_of_thinking_clearly = create_ssr_component(($$result, $$props, $$bindings, slots) => {
	return `<h2 id="${'4-if-50-million-people-say-something-foolish-it-is-still-foolish'}"><a href="${'#4-if-50-million-people-say-something-foolish-it-is-still-foolish'}">4. if 50 million people say something foolish, it is still foolish</a></h2>
<p>You are on your way to a concert. At an intersection, you encounter a group of
people, all staring at the sky. Without even thinking about it, you peer upwards
too. Why? Social proof. In the middle of the concert, when the soloist is displaying
absolute mastery, someone begins to clap and suddenly the whole room joins in.
You do, too. Why? Social proof. After the concert you go to the coat check to pick
up your coat. You watch how the people in front of you place a coin on a plate,
even though, officially, the service is included in the ticket price. What do you do?
You probably leave a tip as well.</p>
<p>Social proof, sometimes roughly termed the herd instinct, dictates that
individuals feel they are behaving correctly when they act the same as other
people. In other words, the more people who follow a certain idea, the better
(truer) we deem the idea to be. And the more people who display a certain
behaviour the more appropriate this behaviour is judged to be by others. This is,
of course, absurd.
Social proof is the evil behind bubbles and stock market panic. It exists in
fashion, management techniques, hobbies, religion and diets. It can paralyse
whole cultures, such as when sects commit collective suicide.</p>
<p>Why do we act like this? Well, in the past, following others was a good survival
strategy. Suppose that 50,000 years ago, you were travelling around the
Serengeti with your hunter-gatherer friends, and suddenly they all bolted. What
would you have done? Would you have stayed put, scratching your head, and
weighing up whether what you were looking at was a lion or something that just
looked like a lion but was in fact a harmless animal that could serve as a great
protein source? No, you would have sprinted after your friends. Later on, when
you were safe, you could have reflected on what the ‘lion’ had actually been.
Those who acted differently from the group – and I am sure there were some –
exited the gene pool. We are the direct descendants of those who copied the
others’ behaviour. This pattern is so deeply rooted in us that we still use it today,
even when it offers no survival advantage, which is most of the time.</p>
<p>Only a few cases come to mind where social proof is of value. For example, if you find
yourself hungry in a foreign city and don’t know a good restaurant, it makes sense
to pick the one that’s full of locals. In other words, you copy the locals’ behaviour.</p>
<p>The advertising industry benefits greatly from our weakness for social proof.
This works well when a situation is unclear (such as deciding among various car
makes, cleaning products, beauty products etc. with no obvious advantages or
disadvantages), and where people ‘like you and me’ appear.
So, be sceptical whenever a company claims its product is better because it is
‘the most popular’. How is a product better simply because it sells the most units?</p>
<p>And remember novelist W. Somerset Maugham’s wise words: ‘If 50 million
people say something foolish, it is still foolish.’</p>
<h2 id="${'5-why-you-should-forget-the-past'}"><a href="${'#5-why-you-should-forget-the-past'}">5. why you should forget the past</a></h2>
<p>The film was dire. After an hour, I whispered to my wife: ‘Come on, let’s go home.’
She replied: ‘No way. We’re not throwing away $30.’ ‘That’s no reason to stay,’ I
protested. ‘The money’s already gone. This is the sunk cost fallacy at work – a
thinking error!’ She glared at me as if she had just bitten off a piece of lemon. OK,
I sometimes go overboard on the subject, itself an error called déformation
professionnelle (see chapter 92). ‘We have spent the $30 regardless of whether
we stay or leave, so this factor should not play a role in our decision,’ I said,
desperately trying to clarify the situation. Needless to say, I gave in in the end and
sank back down in my seat.
The next day, I sat in a marketing meeting. Our advertising campaign had been
running for four months and had not met even one of its goals. I was in favour of
scrapping it. The advertising manager resisted, saying: ‘But we’ve invested so
much money in it. If we stop now, it’ll all have been for nothing.’ Another victim of
the sunk cost fallacy.
A friend struggled for years in a troubled relationship. His girlfriend cheated on
him time and again. Each time, she came back repentant and begged for
forgiveness. He explained it to me this way: ‘I’ve invested so much energy in the
relationship, it would be wrong to throw it away.’ A classic case of the sunk cost
fallacy.
The sunk cost fallacy is most dangerous when we have invested a lot of time,
money, energy or love in something. This investment becomes a reason to carry
on, even if we are dealing with a lost cause. The more we invest, the greater the
sunk costs are, and the greater the urge to continue becomes.
Investors frequently fall victim to the sunk cost fallacy. Often they base their
trading decisions on acquisition prices. ‘I lost so much money with this stock, I
can’t sell it now,’ they say. This is irrational. The acquisition price should play no
role. What counts is the stock’s future performance (and the future performance of
alternative investments). Ironically, the more money a share loses, the more
investors tend to stick by it.
This irrational behaviour is driven by a need for consistency. After all,
consistency signifies credibility. We find contradictions abominable. If we decide
to cancel a project halfway through, we create a contradiction: we admit that we
once thought differently. Carrying on with a meaningless project delays this
painful realisation and keeps up appearances.
Concorde is a prime example of a government deficit project. Even though both
parties, Britain and France, had long known that the supersonic aircraft business
would never work, they continued to invest enormous sums of money in it – if only
to save face. Abandoning the project would have been tantamount to admitting
defeat. The sunk cost fallacy is therefore often referred to as the Concorde effect.
It leads to costly, even disastrous errors of judgement. The Americans extended
their involvement in the Vietnam War because of this. Their thinking: ‘We’ve
already sacrificed so much for this war; it’d be a mistake to give up now.’
‘We’ve come this far?…&#39; ‘I’ve read so much of this book already?…&#39; ‘But I’ve
spent two years doing this course?…&#39; If you recognise any of these thought
patterns, it shows that the sunk cost fallacy is at work in a corner of your brain.
Of course, there may be good reasons to continue investing in something to
finalise it. But beware of doing so for the wrong reasons, such as to justify nonrecoverable investments. Rational decision-making requires you to forget about
the costs incurred to date. No matter how much you have already invested, only
your assessment of the future costs and benefits counts.</p>
<h2 id="${'6-dont-accept-free-drinks'}"><a href="${'#6-dont-accept-free-drinks'}">6. don’t accept free drinks</a></h2>
<p>Reciprocity
Not so long ago, you may have come across disciples of the Hare Krishna sect
floating around in saffron-coloured robes as you hurried to catch a flight or a train
to your destination. A member of the sect presented you with a small flower and a
smile. If you’re like most people, you took the flower, if only not to be rude. If you
tried to refuse, you would have heard a gentle ‘Take it, this is our gift to you.’ If
you wanted to dispose of the flower in the next trashcan, you found that there
were already a few there. But that was not the end. Just as your bad conscience
started to tug at you, another disciple of Krishna approached you, this time asking
for a donation. In many cases, this plea was successful – and so pervasive that
many airports banned the sect from the premises.
Psychologist Robert Cialdini can explain the success of this and other such
campaigns. He has studied the phenomenon of reciprocity and has established
that people have extreme difficulty being in another person’s debt.
Many NGOs and philanthropic organisations use exactly the same techniques:
first give, then take. Last week, a conservation organisation sent me an envelope
full of postcards featuring all sorts of idyllic landscapes. The accompanying letter
assured me that the postcards were a gift to be kept, whether or not I decided to
donate to their organisation. Even though I understood the tactic, it took a little
willpower and ruthlessness to throw them in the trash.
Unfortunately, this kind of gentle blackmail – you could also call it corruption –
is widespread. A supplier of screws invites a potential customer to join him at a
big sports game. A month later, it’s time to order screws. The desire not to be in
debt is so strong that the buyer gives in and places an order with his new friend.
It is also an ancient technique. We find reciprocity in all species whose food
supplies are subject to high fluctuations. Suppose you are a hunter-gatherer. One
day you are lucky and kill a deer. You can’t possibly eat all of it in a day, and
refrigerators are still a few centuries away. You decide to share the deer with the
group, which ensures that you will benefit from others’ spoils when your haul is
less impressive. The bellies of your buddies serve as your refrigerator.
Reciprocity is a very useful survival strategy, a form of risk management.
Without it, humanity – and countless species of animal – would be long extinct. It
is at the core of cooperation between people who are not related to each other
and a necessary ingredient for economic growth and wealth creation. There
would be no global economy without it – there would be no economy at all. That’s
the good side of reciprocity.
But there is also an ugly side of reciprocity: retaliation. Revenge breeds
counter-revenge and you soon find yourself in a full-scale war. Jesus preached
that we should break this cycle by turning the other cheek, which proves very
difficult to do. So compelling is the pull of reciprocity even when the stakes are far
less high.
Several years ago, a couple invited me and my wife to dinner. We had known
this couple casually for quite some time. They were nice, but far from entertaining.
We couldn’t think of a good excuse to refuse, so we accepted. Things played out
exactly as we had imagined: the dinner party was beyond tedious. Nevertheless,
we felt obliged to invite them to our home a few months later. The constraint of
reciprocity had now presented us with two wearisome evenings. And, lo and
behold, a few weeks later a follow-up invitation from them arrived. I wonder how
many dinner parties have been endured in the name of reciprocity, even if the
participants would have preferred to drop out of the vicious cycle years ago.</p>
<p>In much the same way, if someone approaches you in the supermarket,
whether to offer you a taste of wine, a chunk of cheese or a handful of olives, my
best advice is to refuse their offer – unless you want to end up with a refrigerator
full of stuff you don’t even like.</p>
<h2 id="${'7-beware-the-special-case'}"><a href="${'#7-beware-the-special-case'}">7. beware the special case</a></h2>
<p>Confirmation Bias (Part 1)
Gil wants to lose weight. He selects a particular diet and checks his progress on
the scales every morning. If he has lost weight, he pats himself on the back and
considers the diet a success. If he has gained weight, he writes it off as a normal
fluctuation and forgets about it. For months, he lives under the illusion that the diet
is working, even though his weight remains constant. Gil is a victim of the
confirmation bias – albeit a harmless form of it.
The confirmation bias is the mother of all misconceptions. It is the tendency to
interpret new information so that it becomes compatible with our existing theories,
beliefs and convictions. In other words, we filter out any new information that
contradicts our existing views (‘disconfirming evidence’). This is a dangerous
practice. ‘Facts do not cease to exist because they are ignored,’ said writer
Aldous Huxley. However, we do exactly that, as super-investor Warren Buffett
knows: ‘What the human being is best at doing, is interpreting all new information
so that their prior conclusions remain intact.’
The confirmation bias is alive and well in the business world. One example: an
executive team decides on a new strategy. The team enthusiastically celebrates
any sign that the strategy is a success. Everywhere the executives look, they see
plenty of confirming evidence, while indications to the contrary remain unseen or
are quickly dismissed as ‘exceptions’ or ‘special cases’. They have become blind
to disconfirming evidence.
What can you do? If the word ‘exception’ crops up, prick up your ears. Often it
hides the presence of disconfirming evidence. It pays to listen to Charles Darwin:
from his youth, he set out systematically to fight the confirmation bias. Whenever
observations contradicted his theory, he took them very seriously and noted them
down immediately. He knew that the brain actively ‘forgets’ disconfirming
evidence after a short time. The more correct he judged his theory to be, the more
actively he looked for contradictions.
The following experiment shows how much effort it takes to question your own
theory. A professor presented his students with the number sequence 2–4–6.
They had to calculate the underlying rule that the professor had written on the
back of a sheet of paper. The students had to provide the next number in the
sequence, to which the professor would reply ‘fits the rule’ or ‘does not fit the
rule’. The students could guess as many numbers as they wanted, but could try to
identify the rule only once. Most students suggested 8 as the next number, and
the professor replied: ‘Fits the rule.’ To be sure, they tried 10, 12 and 14. The
professor replied each time: ‘Fits the rule.’ The students concluded that: ‘The rule
is to add two to the last number.’ The professor shook his head: ‘That is not the
rule.’
One shrewd student tried a different approach. He tested out the number -2.
The professor said ‘Does not fit the rule.’ ‘Seven?’ he asked. ‘Fits the rule.’ The
student tried all sorts of numbers -24, 9, -43?…?Apparently he had an idea, and
he was trying to find a flaw with it. Only when he could no longer find a counterexample, the student said: ‘The rule is this: the next number must be higher than
the previous one.’ The professor turned over the sheet of paper, and this was
exactly what he’d written down.
What distinguished the resourceful student from the others? While the majority
of students sought merely to confirm their theories, he tried to find fault with his,
consciously looking for disconfirming evidence. You might think: ‘Good for him,
but not the end of the world for the others.’ However, falling for the confirmation
bias is not a petty intellectual offence. How it affects our lives will be revealed in
the next chapter.</p>
<h2 id="${'8-murder-your-darlings'}"><a href="${'#8-murder-your-darlings'}">8. murder your darlings</a></h2>
<p>Confirmation Bias (Part 2)
In the previous chapter, we met the father of all fallacies, the confirmation bias.
We are forced to establish beliefs about the world, our lives, the economy,
investments, our careers and more. We deal mostly in assumptions, and the more
nebulous these are, the stronger the confirmation bias. Whether you go through
life believing that ‘people are inherently good’ or ‘people are inherently bad’, you
will find daily proof to support your case. Both parties, the philanthropists and the
misanthropes, simply filter disconfirming evidence (evidence to the contrary) and
focus instead on the do-gooders and dictators who support their worldviews.
Astrologers and economists operate on the same principle. They utter
prophecies so vague that any event can substantiate them: ‘In the coming weeks
you will experience sadness,’ or ‘in the medium term, the pressure on the dollar
will increase.’ But what is the medium term? What will cause the dollar to
depreciate? And, depreciation measured against what – gold, yen, pesos, wheat,
residential property in Manhattan, the average price of a hot dog?
Religious and philosophical beliefs represent an excellent breeding ground for
the confirmation bias. Here, in soft, spongy terrain, it grows wild and free. For
example, worshippers always find evidence for God’s existence, even though he
never shows himself overtly – except to illiterates in the desert and in isolated
mountain villages. It is never to the masses in, say, Frankfurt or New York.
Counter-arguments are dismissed by the faithful, demonstrating just how powerful
the confirmation bias is.
No professionals suffer more from the confirmation bias than business
journalists. Often, they formulate an easy theory, pad it out with two or three
pieces of ‘evidence’ and call it a day. For example: ‘Google is so successful
because the company nurtures a culture of creativity.’ Once this idea is on paper,
the journalist corroborates it by mentioning a few other prosperous companies
that foster ingenuity. Rarely does the writer seek out disconfirming evidence,
which in this instance would be struggling businesses that live and breathe
creativity or, conversely, flourishing firms that are utterly uncreative. Both groups
have plenty of members, but the journalist simply ignores them. If he or she were
to mention just one, the storyline would be ruined.
Self-help and get-rich-quick books are further examples of blinkered
storytelling. Their shrewd authors collect piles of proof to pump up the most banal
of theories, such as ‘meditation is the key to happiness.’ Any reader seeking
disconfirming evidence does so in vain: nowhere in these books do we see
people who lead fulfilled lives without meditation, or those who, despite
meditation, are still sad.
The Internet is particularly fertile ground for the confirmation bias. To stay
informed, we browse news sites and blogs, forgetting that our favoured pages
mirror our existing values, be they liberal, conservative or somewhere in between.
Moreover, a lot of sites now tailor content to personal interests and browsing
history, causing new and divergent opinions to vanish from the radar altogether.
We inevitably land in communities of like-minded people, further reinforcing our
convictions – and the confirmation bias.
Literary critic Arthur Quiller-Couch had a memorable motto: ‘Murder your
darlings.’ This was his advice to writers who struggled with cutting cherished but
redundant sentences. Quiller-Couch’s appeal is not just for hesitant hacks, but for
all of us who suffer from the deafening silence of assent. To fight against the
confirmation bias, try writing down your beliefs – whether in terms of worldview,
investments, marriage, healthcare, diet, career strategies – and set out to find
disconfirming evidence. Axeing beliefs that feel like old friends is hard work, but
imperative.</p>
<h2 id="${'9-dont-bow-to-authority'}"><a href="${'#9-dont-bow-to-authority'}">9. don’t bow to authority</a></h2>
<p>Authority Bias</p>
<p>The first book of the Bible explains what happens when we disobey a great
authority: we get ejected from paradise. This is also what less celestial authorities
would have us believe - political pundits, scientists, doctors, CEOs, economists,
government heads, sports commentators, consultants and stock market gurus.</p>
<p>Up until 1900 it was discernibly wiser for patients to avoid doctor’s
visits; too often the ‘treatment’ only worsened the illness, due to poor hygiene and
folk practices such as bloodletting.</p>
<p>Psychologist Stanley Milgram demonstrated the authority bias most clearly in
an experiment in 1961. His subjects were instructed to administer ever-increasing
electrical shocks to a person sitting on the other side of a pane of glass. They
were told to start with 15 volts, then 30V, 45V and so on, until they reached the
maximum – a lethal dose of 450V. In reality, no electrical current was actually
flowing; Milgram used an actor to play the role of victim, but those charged with
administering the shocks didn’t know that. The results were, well, shocking: as
the person in the other room wailed and writhed in pain, and the subject
administering the shock wanted to stop, the professor would say, ‘Keep going, the
experiment depends on it.’ The majority of people continued with the
electrocution. More than half of the participants went all the way up to maximum
voltage – out of sheer obedience to authority.</p>
<p>Many companies are light years from this sort of foresight. Especially at risk are
firms with domineering CEOs, where employees are likely to keep their ‘lesser’
opinions to themselves – much to the detriment of the business.
Authorities crave recognition and constantly find ways to reinforce their status.
Doctors and researchers sport white coats. Bank directors don suits and ties.
Kings wear crowns. Members of the military wield rank badges. Today, even
more symbols and props are used to signal expertise: from appearances on talk
shows and on the covers of magazines, to book tours and their own Wikipedia
entries. Authority changes much like fashion does, and society follows it just as
much.</p>
<p>In conclusion: whenever you are about to make a decision, think about which
authority figures might be exerting an influence on your reasoning. And when you
encounter one in the flesh, do your best to challenge him or her.</p>
<h2 id="${'leave-your-supermodel-friends-at-home'}"><a href="${'#leave-your-supermodel-friends-at-home'}">LEAVE YOUR SUPERMODEL FRIENDS AT HOME</a></h2>
<p>Contrast Effect</p>
<p>In his book Influence, Robert Cialdini tells the story of two brothers, Sid and
Harry, who ran a clothing store in 1930s America. Sid was in charge of sales and
Harry led the tailoring department. Whenever Sid noticed that the customers who
stood before the mirror really liked their suits, he became a little hard of hearing.
He would call to his brother: ‘Harry, how much for this suit?’ Harry would look up
from his cutting table and shout back: ‘For that beautiful cotton suit, $42.’ (This
was a completely inflated price at that time.) Sid would pretend he hadn’t
understood: ‘How much?’ Harry would yell again: ‘Forty-two dollars!’ Sid would
then turn to his customer and report: ‘He says $22.’ At this point, the customer
would have quickly put the money on the table and hastened from the store with
the suit before poor Sid noticed his ‘mistake’.</p>
<p>Maybe you know the following experiment from your schooldays: take two
buckets. Fill the first with lukewarm water and the second with ice water. Dip your
right hand into the ice water for one minute. Then put both hands into the
lukewarm water. What do you notice? The lukewarm water feels as it should to
the left hand but piping hot to the right hand.</p>
<p>Both of these stories epitomise the contrast effect: we judge something to be
beautiful, expensive or large if we have something ugly, cheap or small in front of
us. We have difficulty with absolute judgements.
The contrast effect is a common misconception. You order leather seats for
your new car because compared to the $60,000 price tag on the car, $3,000
seems a pittance. All industries that offer upgrade options exploit this illusion.
The contrast effect is at work in other places, too. Experiments show that
people are willing to walk an extra ten minutes to save $10 on food. But those
same people wouldn’t dream of walking ten minutes to save $10 on a thousanddollar suit. An irrational move because ten minutes is ten minutes, and $10 is
$10. Logically, you should walk back in both cases or not at all.
Without the contrast effect, the discount business would be completely
untenable. A product that has been reduced from $100 to $70 seems better value
than a product that has always cost $70. The starting price should play no role.
The other day an investor told me: ‘The share is a great value because it’s 50 per
cent below the peak price.’ I shook my head. A share price is never ‘low’ or ‘high’.
It is what it is, and the only thing that matters is whether it goes up or down from
that point.
When we encounter contrasts, we react like birds to a gunshot: we jump up and
get moving. Our weak spot: we don’t notice small, gradual changes. A magician
can make your watch vanish because, when he presses on one part of your body,
you don’t notice the lighter touch on your wrist as he relieves you of your Rolex.
Similarly, we fail to notice how our money disappears. It constantly loses its
value, but we do not notice because inflation happens over time. If it were
imposed on us in the form of a brutal tax (and basically that’s what it is), we would
be outraged.
The contrast effect can ruin your whole life: a charming woman marries a fairly
average man. But because her parents were awful people, the ordinary man
appears to be a prince.</p>
<p>One final thought: bombarded by advertisements featuring supermodels, we
now perceive beautiful people as only moderately attractive. If you are seeking a
partner, never go out in the company of your supermodel friends. People will find
you less attractive than you really are. Go alone or, better yet, take two ugly
friends.</p>
<h2 id="${'11-why-we-prefer-a-wrong-map-to-no-map-at-all'}"><a href="${'#11-why-we-prefer-a-wrong-map-to-no-map-at-all'}">11. why we prefer a wrong map to no map at all</a></h2>
<p>Availability Bias</p>
<p>‘Smoking can’t be that bad for you: my grandfather smoked three packs of
cigarettes a day and lived to be more than 100.’ Or: ‘Manhattan is really safe. I
know someone who lives in the middle of the Village and he never locks his door.
Not even when he goes on vacation, and his apartment has never been broken
into.’ We use statements like these to try to prove something, but they actually
prove nothing at all. When we speak like this, we succumb to the availability bias.
Are there more English words that start with a K or more words with K as their
third letter? Answer: more than twice as many English words have K in third
position than start with a K. Why do most people believe the opposite is true?
Because we can think of words beginning with a K more quickly. They are more
available to our memory.</p>
<p>The availability bias says this: we create a picture of the world using the
examples that most easily come to mind. This is absurd, of course, because in
reality things don’t happen more frequently just because we can conceive of them
more easily.</p>
<p>Thanks to the availability bias, we travel through life with an incorrect risk map
in our heads. Thus, we systematically overestimate the risk of being the victim of
a plane crash, a car accident or a murder. And we underestimate the risk of dying
from less spectacular means, such as diabetes or stomach cancer. The chances
of bomb attacks are much rarer than we think, and the chances of suffering
depression are much higher. We attach too much likelihood to spectacular, flashy
or loud outcomes. Anything silent or invisible we downgrade in our minds. Our
brains imagine show-stopping outcomes more readily than mundane ones. We
think dramatically, not quantitatively.</p>
<p>Doctors often fall victim to the availability bias. They have their favourite
treatments, which they use for all possible cases. More appropriate treatments
may exist, but these are in the recesses of the doctors’ minds. Consequently they
practise what they know. Consultants are no better. If they come across an
entirely new case, they do not throw up their hands and sigh: ‘I really don’t know
what to tell you.’ Instead they turn to one of their more familiar methods, whether
or not it is ideal.</p>
<p>If something is repeated often enough, it gets stored at the forefront of our
minds. It doesn’t even have to be true.</p>
<p>The availability bias has an established seat at the corporate board’s table, too.
Board members discuss what management has submitted – usually quarterly
figures – instead of more important things, such as a clever move by the
competition, a slump in employee motivation or an unexpected change in
customer behaviour. They tend not to discuss what’s not on the agenda.</p>
<p>In addition, people prefer information that is easy to obtain, be it economic data or
recipes. They make decisions based on this information rather than on more
relevant but harder to obtain information – often with disastrous results.</p>
<p>It is as if you were in a foreign city without a map, and then pulled out one for your home town and simply used that.We prefer wrong information to no information. Thus, the availability bias has presented the banks with billions in losses.</p>
<p>Solution: Fend it off by spending time with people who think differently than you think – people whose experiences and expertise are different than yours. We require others’ input to overcome the availability bias.</p>
<h2 id="${'12-why-no-pain-no-gain-should-set-alarm-bells-ringing'}"><a href="${'#12-why-no-pain-no-gain-should-set-alarm-bells-ringing'}">12. WHY ‘NO PAIN, NO GAIN’ SHOULD SET ALARM BELLS RINGING</a></h2>
<p>The It’ll-Get-Worse-Before-It-Gets-Better Fallacy</p>
<p>A few years ago, I was on vacation in Corsica and fell sick. The symptoms were
new to me, and the pain was growing by the day. Eventually I decided to seek
help at a local clinic. A young doctor began to inspect me, prodding my stomach,
gripping my shoulders and knees and then poking each vertebra. I began to
suspect that he had no idea what my problem was, but I wasn’t really sure so I
simply endured the strange examination. To signal its end, he pulled out his
notebook and said: ‘Antibiotics. Take one tablet three times a day. It’ll get worse
before it gets better.’ Glad that I now had a treatment, I dragged myself back to my
hotel room with the prescription in hand.</p>
<p>The pain grew worse and worse – just as the doctor had predicted. The doctor
must have known what was wrong with me after all. But, when the pain hadn’t
subsided after three days, I called him. ‘Increase the dose to five times a day. It’s
going to hurt for a while more,’ he said. After two more days of agony, I finally
called the international air ambulance. The Swiss doctor diagnosed appendicitis
and operated on me immediately. ‘Why did you wait so long?’ he asked me after
the surgery.</p>
<p>I replied: ‘It all happened exactly as the doctor said, so I trusted him.’
‘Ah, you fell victim to the it’ll-get-worse-before-it-gets-better fallacy. That
Corsican doctor had no idea. Probably just the same type of stand-in you find in
all the tourist places in high season.’</p>
<p>Let’s take another example: a CEO is at his wits’ end. Sales are in the toilet, the
salespeople are unmotivated, and the marketing campaign has sunk without a
trace. In his desperation, he hires a consultant. For $5,000 a day, this man
analyses the company and comes back with his findings: ‘Your sales department
has no vision, and your brand isn’t positioned clearly. It’s a tricky situation. I can
fix it for you – but not overnight. The measures will require sensitivity, and most
likely, sales will fall further before things improve.’ The CEO hires the consultant.
A year later, sales fall, and the same thing happens the next year. Again and
again, the consultant stresses that the company’s progress corresponds closely
to his prediction. As sales continue their slump in the third year, the CEO fires the
consultant.</p>
<p>A mere smokescreen, the It’ll-Get-Worse-Before-It-Gets-Better Fallacy is a
variant of the so-called confirmation bias. If the problem continues to worsen, the
prediction is confirmed. If the situation improves unexpectedly, the customer is
happy and the expert can attribute it to his prowess. Either way he wins.</p>
<p>Suppose you are president of a country, and have no idea how to run it. What
do you do? You predict ‘difficult years’ ahead, ask your citizens to ‘tighten their
belts’, and then promise to improve the situation only after this ‘delicate stage’ of
the ‘cleansing’, ‘purification’ and ‘restructuring’. Naturally you leave the duration
and severity of the period open.</p>
<p>The best evidence of this strategy’s success is Christianity: its literal followers
believe that before we can experience heaven on earth, the world must be
destroyed. Disasters, floods, fires, death – they are all part of the larger plan and
must take place. Believers will view any deterioration of the situation as
confirmation of the prophecy, and any improvement as a gift from God.</p>
<p>In conclusion: if someone says ‘It’ll get worse before it gets better,’ you should
hear alarm bells ringing. But beware: situations do exist where things first dip and
then improve. For example, a career change requires time and often incorporates
loss of pay. The reorganisation of a business also takes time. But in all these
cases, we can see relatively quickly if the measures are working. The milestones
are clear and verifiable. Look to these rather than to the heavens.</p>
<h2 id="${'13-even-true-stories-are-fairytales'}"><a href="${'#13-even-true-stories-are-fairytales'}">13. EVEN TRUE STORIES ARE FAIRYTALES</a></h2>
<p>Story Bias</p>
<p>Life is a muddle, as intricate as a Gordian knot. Imagine that an invisible Martian
decides to follow you around with an equally invisible notebook, recording what
you do, think and dream. The rundown of your life would consist of entries such
as ‘drank coffee, two sugars’, ‘stepped on a thumbtack and swore like a sailor’,
‘dreamed that I kissed the neighbour’, ‘booked vacation, Maldives, now nearly out
of money’, ‘found hair sticking out of ear, plucked it straight away’ and so on. We
like to knit this jumble of details into a neat story. We want our lives to form a
pattern that can be easily followed. Many call this guiding principle ‘meaning’. If
our story advances evenly over the years, we refer to it as ‘identity’. ‘We try on
stories as we try on clothes,’ said Max Frisch, a famous Swiss novelist.
We do the same with world history, shaping the details into a consistent story.
Suddenly we ‘understand’ certain things; for example, why the Treaty of
Versailles led to the Second World War, or why Alan Greenspan’s loose
monetary policy created the collapse of Lehman Brothers. We comprehend why
the Iron Curtain had to fall or why Harry Potter became a best-seller. Here, we
speak about ‘understanding’, but these things cannot be understood in the
traditional sense. We simply build the meaning into them afterward. Stories are
dubious entities. They simplify and distort reality, and filter things that don’t fit. But
apparently we cannot do without them. Why remains unclear. What is clear is that
people first used stories to explain the world, before they began to think
scientifically, making mythology older than philosophy. This has led to the story
bias.</p>
<p>In the media, the story bias rages like wildfire. For example: a car is driving over a bridge when the structure suddenly collapses. What do we read the next day? We hear the tale of the unlucky driver, where he came from and where he was going. We read his biography: born somewhere, grew up somewhere else,
earned a living as something. If he survives and can give interviews, we hear
exactly how it felt when the bridge came crashing down. The absurd thing: not
one of these stories explains the underlying cause of the accident. Skip past the
driver’s account and consider the bridge’s construction: where was the weak
point? Was it fatigue? If not, was the bridge damaged? If so, by what? Was a
proper design even used? Where are there other bridges of the same design?
The problem with all these questions is that, though valid, they just don’t make for
a good yarn. Stories attract us; abstract details repel us. Consequently,
entertaining side issues and backstories are prioritised over relevant facts. (On
the upside, if it were not for this, we would be stuck with only non-fiction books.)
Here are two stories from the English novelist E. M. Forster. Which one would
you remember better? A) ‘The king died, and the queen died.’ B) ‘The king died,
and the queen died of grief.’ Most people will retain the second story more easily.
Here, the two deaths don’t just take place successively; they are emotionally
linked. Story A is a factual report, but story B has ‘meaning’. According to
information theory, we should be able to hold on to A better: it is shorter. But our
brains don’t work that way.
Advertisers have learned to capitalise on this too. Instead of focusing on an
item’s benefits, they create a story around it. Objectively speaking, narratives are
irrelevant, but still we find them irresistible. Google illustrated this masterfully in its
Super Bowl commercial from 2010, ‘Google Parisian Love’. Take a look at it on YouTube.</p>
<p>From our own life stories to global events, we shape everything into meaningful
stories. Doing so distorts reality and affects the quality of our decisions, but there
is a remedy: pick these apart. Ask yourself: what are they trying to hide? Visit the
library and spend half a day reading old newspapers. You will see that events
that today look connected weren’t so at the time. To experience the effect once
more, try to view your life story out of context. Dig into your old journals and notes,
and you’ll see that your life has not followed a straight arrow leading to today, but has been a series of unplanned unconnected events and experiences, as we’ll see in the next chapter.</p>
<p>Whenever you hear a story, ask yourself: who is the sender, what are his intentions and what did he hide under the rug? The omitted elements might not be of relevance. But then again, they might be even more relevant than the
elements featured in the story, such as when ‘explaining’ a financial crisis or the
‘cause’ of war. The real issue with stories: they give us a false sense of
understanding, which inevitably leads us to take bigger risks and urges us to take
a stroll on thin ice.</p>
<h2 id="${'14-why-you-should-keep-a-diary'}"><a href="${'#14-why-you-should-keep-a-diary'}">14. WHY YOU SHOULD KEEP A DIARY</a></h2>
<p>Hindsight Bias</p>
<p>I came across the diaries of my great-uncle recently. In 1932, he emigrated from a
tiny Swiss village to Paris to seek his fortune in the movie industry. In August
1940, two months after Paris was occupied, he noted: ‘Everyone is certain that
the Germans will leave by the end of the year. Their officers also confirmed this to
me. England will fall as fast as France did, and then we will finally have our
Parisian lives back – albeit as part of Germany.’ The occupation lasted four years.
In today’s history books, the German occupation of France seems to form part
of a clear military strategy. In retrospect, the actual course of the war appears the
most likely of all scenarios. Why? Because we have fallen victim to the hindsight bias.</p>
<p>Let’s take a more recent example: in 2007, economic experts painted a rosy
picture for the coming years. However, just twelve months later, the financial
markets imploded. Asked about the crisis, the same experts enumerated its
causes: monetary expansion under Greenspan, lax validation of mortgages,
corrupt rating agencies, low capital requirements, and so forth. In hindsight, the
reasons for the crash seem painfully obvious.</p>
<p>The hindsight bias is one of the most prevailing fallacies of all. We can aptly
describe it as the ‘I told you so’ phenomenon: in retrospect, everything seems
clear and inevitable. If a CEO becomes successful due to fortunate circumstances
he will, looking back, rate the probability of his success a lot higher than it
actually was. Similarly, following Ronald Reagan’s massive election victory over
Jimmy Carter in 1980, commentators announced his appointment to be
foreseeable, even though the election lay on a knife-edge until a few days before
the final vote.</p>
<p>Today, business journalists opine that Google’s dominance was
predestined, even though each of them would have snorted had such a prediction been made in 1998.</p>
<p>So why is the hindsight bias so perilous? Well, it makes us believe we are
better predictors than we actually are, causing us to be arrogant about our
knowledge and consequently to take too much risk. And not just with global
issues: ‘Have you heard? Sylvia and Chris aren’t together any more. It was
always going to go wrong, they were just so different.’ Or: ‘They were just so
similar.’ Or: ‘They spent too much time together.’ Or even: ‘They barely saw one
another.’</p>
<p>Overcoming the hindsight bias is not easy. Studies have shown that people
who are aware of it fall for it just as much as everyone else. So, I’m very sorry, but
you’ve just wasted your time reading this chapter.</p>
<p>If you’re still with me, I have one final tip, this time from personal rather than
professional experience: keep a journal. Write down your predictions – for
political changes, your career, your weight, the stock market and so on. Then,
from time to time, compare your notes with actual developments. You will be
amazed at what a poor forecaster you are.</p>
<p>Don’t forget to read history too – not
the retrospective, compacted theories compiled in textbooks, but the diaries, oral
histories and historical documents from the period. If you can’t live without news,
read newspapers from five, ten or twenty years ago. This will give you a much
better sense of just how unpredictable the world is. </p>
<p>Hindsight may provide temporary comfort to those overwhelmed by complexity, but as for providing
deeper revelations about how the world works, you’ll benefit by looking elsewhere.</p>
<h2 id="${'15-why-you-systematically-overestimate-your-knowledge-and-abilities'}"><a href="${'#15-why-you-systematically-overestimate-your-knowledge-and-abilities'}">15. WHY YOU SYSTEMATICALLY OVERESTIMATE YOUR KNOWLEDGE AND ABILITIES</a></h2>
<p>Overconfidence Effect</p>
<p>My favourite musician, Johann Sebastian Bach, was anything but a one-hit
wonder. He composed numerous works. How many there were I will reveal at the
end of this chapter. But for now, here’s a small assignment: how many concertos
do you think Bach composed? Choose a range, for example, between 100 and
500, aiming for an estimate that is 98% correct and only 2% off.</p>
<p>How much confidence should we have in our own knowledge? Psychologists
Howard Raiffa and Marc Alpert, wondering the same thing, have interviewed
hundreds of people in this way. They have asked participants to estimate the total
egg production in the U.S., or the number of physicians and surgeons listed in the
Yellow Pages of the phone directory for Boston, or the number of foreign
automobiles imported into the U.S., or even the toll collections of the Panama
Canal in millions of dollars. Subjects could choose any range they liked, with the
aim of not being wrong more than 2% of the time. The results were amazing. In
the final tally, instead of just 2%, they were off 40% of the time. The researchers
dubbed this amazing phenomenon overconfidence.</p>
<p>Overconfidence also applies to forecasts, such as stock market performance
over a year or your firm’s profits over three years. We systematically overestimate
our knowledge and our ability to predict – on a massive scale. The
overconfidence effect does not deal with whether single estimates are correct or
not. Rather, it measures the difference between what people really know and
what they think they know. What’s surprising is this: experts suffer even more from
overconfidence than laypeople do. If asked to forecast oil prices in five years’
time, an economics professor will be as wide of the mark as a zookeeper will. However, the professor will offer his forecast with certitude.</p>
<p>Overconfidence does not stop at economics: in surveys, 84% of Frenchmen
estimate that they are above-average lovers. Without the overconfidence effect,
that figure should be exactly 50% – after all, the statistical ‘median’ means 50%
should rank higher and 50% should rank lower. In another survey, 93% of the
U.S. students asked estimated themselves to be ‘above average’ drivers. And
68% of the faculty at the University of Nebraska rated themselves in the top 25%
for teaching ability. Entrepreneurs and those wishing to marry also deem
themselves to be different: they believe they can beat the odds. In fact,
entrepreneurial activity would be a lot lower if overconfidence did not exist. For
example, every restaurateur hopes to establish the next Michelin-starred
restaurant, even though statistics show that most close their doors after just three
years. The return on investment in the restaurant business lies chronically below
zero.</p>
<p>Hardly any major projects exist that are completed in less time and at a lower
cost than forecasted. Some delays and cost overruns are even legendary, such
as the Airbus A400M, the Sydney Opera House and Boston’s Big Dig. The list
can be added to at will. Why is that? Here, two effects act in unison. First, you
have classic overconfidence. Second, those with a direct interest in the project
have an incentive to underestimate the costs: consultants, contractors and
suppliers seek follow-up orders. Builders feel bolstered by the optimistic figures
and, through their activities, politicians get more votes. We will examine this
strategic misrepresentation (Chapter 89) later in the book.</p>
<p>What makes overconfidence so prevalent and its effect so confounding is that it is not driven by incentives; it is raw and innate. And it’s not counterbalanced by
the opposite effect, ‘underconfidence’, which doesn’t exist. </p>
<p>No surprise to some readers: overconfidence is more pronounced in men – women tend not to
overestimate their knowledge and abilities as much. Even more troubling:
optimists are not the only victims of overconfidence. Even self-proclaimed
pessimists overrate themselves - just less extremely.</p>
<p>In conclusion: be aware that you tend to overestimate your knowledge. Be
sceptical of predictions, especially if they come from so-called experts. And with
all plans, favour the pessimistic scenario. This way you have a chance of judging
the situation somewhat realistically.</p>
<p>Back to the question from the beginning: Johann Sebastian Bach composed
1127 works that survived to this day. He may have composed considerably more,
but they are lost</p>
<h2 id="${'16-dont-take-news-anchors-seriously'}"><a href="${'#16-dont-take-news-anchors-seriously'}">16. DON’T TAKE NEWS ANCHORS SERIOUSLY</a></h2>
<p>Chauffeur Knowledge</p>
<p>After receiving the Nobel Prize for Physics in 1918, Max Planck went on tour
across Germany. Wherever he was invited, he delivered the same lecture on new
quantum mechanics. Over time, his chauffeur grew to know it by heart: ‘It has to
be boring giving the same speech each time, Professor Planck. How about I do it
for you in Munich? You can sit in the front row and wear my chauffeur’s cap.</p>
<p>That’d give us both a bit of variety.’ Planck liked the idea, so that evening the
driver held a long lecture on quantum mechanics in front of a distinguished
audience. Later, a physics professor stood up with a question. The driver
recoiled: ‘Never would I have thought that someone from such an advanced city
as Munich would ask such a simple question! My chauffeur will answer it.’
According to Charlie Munger, one of the world’s best investors (and from whom
I have borrowed this story), there are two types of knowledge. First, we have real
knowledge. We see it in people who have committed a large amount of time and
effort to understanding a topic. </p>
<p>The second type is chauffeur knowledge – knowledge from people who have learned to put on a show. Maybe they have a
great voice or good hair, but the knowledge they espouse is not their own. They reel off eloquent words as if reading from a script.</p>
<p>Unfortunately, it is increasingly difficult to separate true knowledge from
chauffeur knowledge. With news anchors, however, it is still easy. These are
actors. Period. Everyone knows it. And yet it continues to astound me how much
respect these perfectly-coiffed script readers enjoy, not to mention how much they
earn moderating panels about topics they barely fathom.</p>
<p>With journalists, it is more difficult. Some have acquired true knowledge. Often they are veteran reporters who have specialised for years in a clearly defined area. They make a serious effort to understand the complexity of a subject and to
communicate it. They tend to write long articles that highlight a variety of cases
and exceptions. The majority of journalists, however, fall into the category of
chauffeur. They conjure up articles off the tops of their heads, or rather, from
Google searches. Their texts are one-sided, short, and – often as compensation
for their patchy knowledge - snarky and self-satisfied in tone.</p>
<p>The same superficiality is present in business. The larger a company, the more
the CEO is expected to possess ‘star quality’. Dedication, solemnity, and
reliability are undervalued, at least at the top. Too often shareholders and
business journalists seem to believe that showmanship will deliver better results,
which is obviously not the case.
To guard against the chauffeur effect, Warren Buffett, Munger’s business
partner, has coined a wonderful phrase, ‘circle of competence’. What lies inside
this circle you understand intuitively; what lies outside, you may only partially
comprehend. One of Munger’s best pieces of advice is: ‘You have to stick within
what I call your circle of competence. You have to know what you understand and
what you don’t understand. It’s not terribly important how big the circle is. But it is
terribly important that you know where the perimeter is.’ Munger underscores this:
‘So you have to figure out what your own aptitudes are. If you play games where
other people have the aptitudes and you don’t, you’re going to lose. And that’s as
close to certain as any prediction that you can make. You have to figure out
where you’ve got an edge. And you’ve got to play within your own circle of
competence.’</p>
<p>In conclusion: be on the lookout for chauffeur knowledge. Do not confuse the company spokesperson, the ringmaster, the newscaster, the schmoozer, the verbiage vendor or the cliché generator with those who possess true knowledge. How do you recognise the difference There is a clear indicator: true experts recognise the limits of what they know and what they do not know. If they find themselves outside their circle of competence, they keep quiet or simply say, ‘I don’t know.’ This they utter unapologetically, even with a certain pride. From chauffeurs, we hear every line except this.</p>
<h2 id="${'17-you-control-less-than-you-think'}"><a href="${'#17-you-control-less-than-you-think'}">17. YOU CONTROL LESS THAN YOU THINK</a></h2>
<p>Illusion of Control</p>
<p>Every day, shortly before nine o’clock, a man with a red hat stands in a square
and begins to wave his cap around wildly. After five minutes he disappears. One
day, a policeman comes up to him and asks: ‘What are you doing?’ ‘I’m keeping
the giraffes away.’ ‘But there aren’t any giraffes here.’ ‘Well, I must be doing a
good job, then.’</p>
<p>A friend with a broken leg was stuck in bed and asked me to pick up a lottery
ticket for him. I went to the store, checked a few boxes, wrote his name on it and
paid. As I handed him the copy of the ticket, he balked. ‘Why did you fill it out? I
wanted to do that. I’m never going to win anything with your numbers!’
‘Do you really think it affects the draw if you pick the numbers?’ I inquired. He
looked at me blankly.</p>
<p>In casinos, most people throw the dice as hard as they can if they need a high
number, and as gingerly as possible if they are hoping for a low number – which
is as nonsensical as football fans thinking they can swing a game by
gesticulating in front of the TV. Unfortunately they share this illusion with many
people who also seek to influence the world by sending out the ‘right’ thoughts
(vibrations, positive energy, karma?…?).</p>
<p>The illusion of control is the tendency to believe that we can influence
something over which we have absolutely no sway. This was discovered in 1965
by two researchers, Jenkins and Ward. Their experiment was simple, consisting
of just two switches and a light. The men were able to adjust when the switches
connected to the light and when not. Even when the light flashed on and off at
random, subjects were still convinced that they could influence it by flicking the
switches.</p>
<p>Or consider this example: an American researcher has been investigating
acoustic sensitivity to pain. For this, he placed people in sound booths and
increased the volume until the subjects signalled him to stop. The two rooms, A
and B, were identical, save one thing: room B had a red panic button on the wall.
The button was purely for show, but it gave participants the feeling that they were
in control of the situation, leading them to withstand significantly more noise. If
you have read Aleksandr Solzhenitsyn, Primo Levi or Viktor Frankl, this finding
will not surprise you: the idea that people can influence their destiny even by a
fraction encouraged these prisoners not to give up hope.</p>
<p>Crossing the street in Los Angeles is a tricky business, but luckily, at the press
of a button, we can stop traffic. Or can we? The button’s real purpose is to make
us believe we have an influence on the traffic lights, and thus we’re better able to
endure the wait for the signal to change with more patience. The same goes for
‘door-open’ and ‘door-close’ buttons in elevators: many are not even connected to
the electrical panel. Such tricks are also designed into open-plan offices: for
some people it will always be too hot, for others too cold. Clever technicians
create the illusion of control by installing fake temperature dials. This reduces
energy bills – and complaints. Such ploys are called ‘placebo buttons’ and they
are being pushed in all sorts of realms.</p>
<p>Central bankers and government officials employ placebo buttons masterfully.
Take, for instance, the federal funds rate, which is an extreme short-term rate, an
overnight rate to be precise. While this rate doesn’t affect long-term interest rates
(which are a function of supply and demand, and an important factor in
investment decisions), the stock market, nevertheless, reacts frenetically to its
every change. Nobody understands why overnight interest rates can have such
an effect on the market, but everybody thinks they do, and so they do. The same
goes for pronouncements made by the Chairman of the Federal Reserve; markets
move, even though these statements inject little of tangible value into the real
economy. They are merely sound waves. And still we allow economic heads to
continue to play with the illusory dials. It would be a real wake-up call if all
involved realised the truth – that the world economy is a fundamentally
uncontrollable system.</p>
<p>And you? Do you have everything under control? Probably less than you think.
Do not think you command your way through life like a Roman emperor. Rather,
you are the man with the red hat. Therefore, focus on the few things of importance
that you can really influence. </p>
<p>For everything else: que sera, sera.</p>
<h2 id="${'18-never-pay-your-lawyer-by-the-hour'}"><a href="${'#18-never-pay-your-lawyer-by-the-hour'}">18. never pay your lawyer by the hour</a></h2>
<p>Incentive Super-Response Tendency</p>
<p>To control a rat infestation, French colonial rulers in Hanoi in the nineteenth
century passed a law: for every dead rat handed in to the authorities, the catcher
would receive a reward. Yes, many rats were destroyed, but many were also bred specially for this purpose.</p>
<p>In 1947, when the Dead Sea scrolls were discovered, archaeologists set a
finder’s fee for each new parchment. Instead of lots of extra scrolls being found,
they were simply torn apart to increase the reward. Similarly, in China in the
nineteenth century, an incentive was offered for finding dinosaur bones. Farmers
located a few on their land, broke them into pieces and cashed in. Modern
incentives are no better: company boards promise bonuses for achieved targets.
And what happens? Managers invest more energy in trying to lower the targets
than in growing the business.</p>
<p>These are examples of the incentive super-response tendency. Credited to
Charlie Munger, this titanic name describes a rather trivial observation: people
respond to incentives by doing what is in their best interests. What is noteworthy
is, first, how quickly and radically people’s behaviour changes when incentives
come into play or are altered and, second, the fact that people respond to the
incentives themselves and not the grander intentions behind them.
Good incentive systems comprise both intent and reward. An example: in
Ancient Rome, engineers were made to stand underneath the construction at
their bridges’ opening ceremonies. Poor incentive systems, on the other hand,
overlook and sometimes even pervert the underlying aim. For example, censoring
a book makes its contents more famous and rewarding bank employees for each
loan sold leads to a miserable credit portfolio. Making CEOs’ pay public didn’t
dampen the astronomical salaries; to the contrary, it pushed them upward.
Nobody wants to be the loser CEO in his industry.</p>
<p>Do you want to influence the behaviour of people or organisations? You could
always preach about values and visions, or you could appeal to reason. But in
nearly every case, incentives work better. These need not be monetary; anything
is useable, from good grades to Nobel Prizes to special treatment in the afterlife.
For a long time I tried to understand what made well-educated nobles from the
Middle Ages bid adieu to their comfortable lives, swing themselves up on to
horses and take part in the Crusades. They were well aware that the arduous ride
to Jerusalem lasted at least six months and passed directly through enemy
territory, yet they took the risk. And then it came to me: the answer lies in incentive
systems. If they came back alive, they could keep the spoils of war and live out
their days as rich men. If they died, they automatically passed on to the afterlife as
martyrs – with all the benefits that came with it. It was win-win.</p>
<p>Imagine for a moment that, instead of demanding enemies’ riches, warriors and
soldiers charged by the hour. We would effectively be incentivising them to take
as long as possible, right? So why do we do just this with lawyers, architects,
consultants, accountants and driving instructors? </p>
<p>=&gt; My advice: forget hourly rates and always negotiate a fixed price in advance.</p>
<p>Be wary, too, of investment advisers endorsing particular financial products.
They are not interested in your financial well-being, but in earning a commission
on these products. The same goes for entrepreneurs’ and investment bankers’
business plans. These are often worthless because, again, the vendors have
their own interests at heart. What is the old adage? ‘Never ask a barber if you
need a haircut.’</p>
<p>In conclusion: keep an eye out for the incentive super-response tendency. If a
person’s or an organisation’s behaviour confounds you, ask yourself what
incentive might lie behind it. I guarantee you that you’ll be able to explain 90% of
the cases this way. What makes up the remaining 10%? Passion, idiocy, psychosis or malice.</p>
<h2 id="${'19-the-dubious-efficacy-of-doctors-consultants-and-psychotherapists'}"><a href="${'#19-the-dubious-efficacy-of-doctors-consultants-and-psychotherapists'}">19. THE DUBIOUS EFFICACY OF DOCTORS, CONSULTANTS AND PSYCHOTHERAPISTS</a></h2>
<p>Regression to Mean
His back pain was sometimes better, sometimes worse. There were days when
he felt like he could move mountains, and those when he could barely move.
When that was the case - fortunately it happened only rarely - his wife would
drive him to the chiropractor. The next day he would feel much more mobile and
would recommend the therapist to everyone.</p>
<p>Another man, younger and with a respectable golf handicap of 12, gushed in a similar fashion about his golf instructor. Whenever he played miserably, he booked an hour with the pro, and lo and behold, in the next game he fared much better.</p>
<p>A third man, an investment adviser at a major bank, invented a sort of ‘rain
dance’, which he performed in the restroom every time his stocks had performed
extremely badly. As absurd as it seemed, he felt compelled to do it: and things
always improved afterward.</p>
<p>What links the three men is a fallacy: the regression-to-mean delusion.
Suppose your region is experiencing a record period of cold weather. In all
probability, the temperature will rise in the next few days, back toward the monthly
average. The same goes for extreme heat, drought or rain. Weather fluctuates
around a mean. The same is true for chronic pain, golf handicaps, stock market
performance, luck in love, subjective happiness and test scores. In short, the
crippling back pain would most likely have improved without a chiropractor. The handicap would have returned to 12 without additional lessons. And the
performance of the investment adviser would also have shifted back toward the
market average – with or without the restroom dance.</p>
<p>Extreme performances are interspersed with less extreme ones. The most successful stock picks from the past three years are hardly going to be the most successful stocks in the coming three years. Knowing this, you can appreciate
why some athletes would rather not make it on to the front pages of the
newspapers: subconsciously they know that the next time they race, they
probably won’t achieve the same top result – which has nothing to do with the
media attention, but is to do with natural variations in performance.</p>
<p>Or, take the example of a division manager who wants to improve employee
morale by sending the least motivated 3% of the workforce on a course. The
result? The next time he looks at motivation levels, the same people will not make
up the bottom few – there will be others. Was the course worth it? Hard to say,
since the group’s motivation levels would probably have returned to their
personal norms even without the training. The situation is similar with patients
who are hospitalised for depression. They usually leave the clinic feeling a little
better. It is quite possible, however, that the stay contributed absolutely nothing.
Another example: in Boston, the lowest-performing schools were entered into a
complex support programme. The following year, the schools had moved up in
the rankings, an improvement that the authorities attributed to the programme
rather than to natural regression to mean.</p>
<p>Ignoring regression to mean can have destructive consequences, such as
teachers (or managers) concluding that the stick is better than the carrot. For
example, following a test the highest performing students are praised, and the
lowest are castigated. In the next exam, other students will probably – purely
coincidentally – achieve the highest and lowest scores. Thus, the teacher concludes that reproach helps and praise hinders. A fallacy that keeps on giving.</p>
<p>In conclusion: when you hear stories such as: ‘I was sick, went to the doctor,
and got better a few days later’ or ‘the company had a bad year, so we got a
consultant in and now the results are back to normal’, look out for our old friend, the regression-to-mean error</p>
<h2 id="${'20-never-judge-a-decision-by-its-outcome'}"><a href="${'#20-never-judge-a-decision-by-its-outcome'}">20. never judge a decision by its outcome</a></h2>
<p>Outcome Bias</p>
<p>A quick hypothesis: say one million monkeys speculate on the stock market. They
buy and sell stocks like crazy and, of course, completely at random. What
happens? After one week, about half of the monkeys will have made a profit and
the other half a loss. The ones that made a profit can stay; the ones that made a
loss you send home. In the second week, one half of the monkeys will still be
riding high, while the other half will have made a loss and are sent home. And so
on. After ten weeks, about 1,000 monkeys will be left – those who have always
invested their money well. After twenty weeks, just one monkey will remain – this
one always, without fail, chose the right stocks and is now a billionaire. Let’s call
him the success monkey.</p>
<p>How does the media react? They will pounce on this animal to understand its
‘success principles’. And they will find some: perhaps the monkey eats more
bananas than the others. Perhaps he sits in another corner of the cage. Or,
maybe he swings headlong through the branches, or he takes long, reflective
pauses while grooming. He must have some recipe for success, right? How else
could he perform so brilliantly? Spot-on for twenty weeks – and that from a simple
monkey? Impossible!</p>
<p>The monkey story illustrates the outcome bias: we tend to evaluate decisions
based on the result rather than on the decision process. This fallacy is also
known as the historian error. A classic example is the Japanese attack on Pearl
Harbor. Should the military base have been evacuated or not? From today’s
perspective: obviously, for there was plenty of evidence that an attack was
imminent. However, only in retrospect do the signals appear so clear. At the time,
in 1941, there was a plethora of contradictory signals. Some pointed to an attack;
others did not. To assess the quality of the decision, we must use the information
available at the time, filtering out everything we know about it post-attack
(particularly that it did indeed take place).</p>
<p>Another experiment: you must evaluate the performance of three heart
surgeons. To do this, you ask each to carry out a difficult operation five times.
Over the years, the probability of dying from these procedures has stabilised at
20%. With surgeon A, no one dies. With surgeon B, one patient dies. With
surgeon C, two die. How do you rate the performance of A, B and C? If you think
like most people, you rate A the best, B the second best, and C the worst. And
thus you’ve just fallen for the outcome bias. You can guess why: the samples are
too small, rendering the results meaningless. You can only really judge a surgeon
if you know something about the field, and then carefully monitor the preparation
and execution of the operation. In other words, you assess the process and not
the result. Alternatively, you could employ a larger sample, if you have enough
patients who need this particular operation: 100 or 1,000 operations. For now it is
enough to know that, with an average surgeon, there is a 33% chance that no one
will die, a 41% chance that one person will die and a 20% chance that two people
will die. That’s a simple probability calculation. What stands out: there is no huge
difference between zero dead and two dead. To assess the three surgeons purely
on the basis of the outcomes would be not only negligent but also unethical.</p>
<p>In conclusion: never judge a decision purely by its result, especially when
randomness or ‘external factors’ play a role. A bad result does not automatically
indicate a bad decision and vice versa. So rather than tearing your hair out about
a wrong decision, or applauding yourself for one that may have only coincidentally led to success, remember why you chose what you did. Were your reasons rational and understandable? Then you would do well to stick with that method, even if you didn’t strike lucky last time.</p>
<h2 id="${'22-less-is-more'}"><a href="${'#22-less-is-more'}">22. less is more</a></h2>
<p>The Paradox of Choice</p>
<p>I’ve counted and researched: my local grocery store stocks 48 varieties of
yogurt, 134 types of red wine, 64 different cleaning products and a grand total of
30,000 items. Amazon, the Internet bookseller, has two million titles available.</p>
<p>And yet, selection is the yardstick of progress. It is what sets us apart from
planned economies and the Stone Age. Yes, abundance makes you giddy, but
there is a limit. When it is exceeded, a surfeit of choices destroys quality of life.
The technical term for this is the <strong>paradox of choice</strong>.</p>
<p>In his book of the same title, psychologist Barry Schwartz describes why this is
so. First, a large selection leads to inner paralysis. To test this, a supermarket set
up a stand where customers could sample twenty-four varieties of jelly. They
could try as many as they liked and then buy them at a discount. The next day,
the owners carried out the same experiment with only six flavours. The result?
They sold ten times more jelly on day two. Why? With such a wide range,
customers could not come to a decision, so they bought nothing. The experiment
was repeated several times with different products. The results were always the
same.</p>
<p>Second, a broader selection leads to poorer decisions. If you ask young people
what is important in a life partner, they reel off all the usual qualities: intelligence, good manners, warmth, the ability to listen, a sense of humour and physical attractiveness. But do they actually take these criteria into account when choosing someone? In the past, a young man from a village of average size could
choose among maybe twenty girls of similar age with whom he went to school.</p>
<p>He knew their families and vice versa, leading to a decision based on several
well-known attributes. Nowadays, in the era of online dating, millions of potential
partners are at our disposal. It has been proven that the stress caused by this
mind-boggling variety is so large that the male brain reduces the decision to one
single criterion: physical attractiveness.</p>
<p>The consequences of this selection process you already know – perhaps even from personal experience.
Finally, large selection leads to discontent. How can you be sure you are
making the right choice when 200 options surround and confound you? The
answer is: you cannot. The more choice you have, the more unsure and therefore
dissatisfied you are afterward.</p>
<p>So, what can you do? Think carefully about what you want before you inspect existing offers. Write down these criteria and stick to them rigidly. Also, realise that you can never make a perfect decision. Aiming for this, given the flood of possibilities, is a form of irrational perfectionism. Instead, learn to love a ‘good’
choice. Yes, even in terms of life partners. Only the best will do? In this age of unlimited variety, rather the opposite is true: ‘good enough’ is the new optimum(except, of course, for you and me).</p>
<h2 id="${'22-you-like-me-you-really-really-like-me'}"><a href="${'#22-you-like-me-you-really-really-like-me'}">22. you like me, you really really like me</a></h2>
<p>Liking Bias</p>
<p>Kevin has just bought two boxes of fine Margaux. He rarely drinks wine – not even Bordeaux – but the sales assistant was so nice, not fake or pushy, just really
likeable. So he bought them.</p>
<p>Joe Girard is considered the most successful car salesman in the world. His tip
for success: ‘There’s nothing more effective in selling anything than getting the
customer to believe, really believe, that you like him and care about him.’ Girard
doesn’t just talk the talk: his secret weapon is sending a card to his customers
each month. Just one sentence salutes them: ‘I like you.’</p>
<p>The liking bias is startlingly simple to understand and yet we continually fall
prey to it. It means this: the more we like someone, the more inclined we are to
buy from or help that person. Still, the question remains: what does ‘likeable’
even mean? According to research, we see people as pleasant if A) they are
outwardly attractive, B) they are similar to us in terms of origin, personality or
interests, and C) they like us. Consequently, advertising is full of attractive
people. Ugly people seem unfriendly and don’t even make it into the background
(see A). In addition to engaging super-attractive types, advertising also employs
‘people like you and me’ (see B) – those who are similar in appearance, accent or
background. In short, the more similar the better. Mirroring is a standard technique
in sales to get exactly this effect. Here, the salesperson tries to copy the gestures,
language, and facial expressions of his prospective client. </p>
<p>If the buyer speaks very slowly and quietly, often scratching his head, it makes sense for the seller to
speak slowly and quietly, and to scratch his head now and then too. That makes
him likeable in the eyes of the buyer, and thus a business deal is more likely.</p>
<p>Finally, it’s not unheard of for advertisers to pay us compliments: how many times
have you bought something ‘because you’re worth it’? Here factor C comes into
play: we find people appealing if they like us. Compliments work wonders, even if
they ring hollow as a drum.</p>
<p>So-called multilevel marketing (selling through personal networks) works solely
because of the liking bias. Though there are excellent plastic containers in the
supermarket for a quarter of the price, Tupperware generates an annual turnover
of two billion dollars. Why? The friends who hold the Tupperware parties meet
the second and third congeniality standard perfectly.</p>
<p>Aid agencies employ the liking bias to great effect. Their campaigns use
beaming children or women almost exclusively. Never will you see a stone-faced,
wounded guerrilla fighter staring at you from billboards – even though he also
needs your support. Conservation organisations also carefully select who gets
the starring role in their advertisements. Have you ever seen a World Wildlife
Fund brochure filled with spiders, worms, algae or bacteria? They are perhaps
just as endangered as pandas, gorillas, koalas and seals – and even more
important for the ecosystem. But we feel nothing for them. The more human a
creature acts, the more similar it is to us, the more we like it. The bone skipper fly
is extinct? Too bad.</p>
<p>Politicians, too, are maestros of the liking bias. Depending on the make-up and
interests of an audience, they emphasise different topics, such as residential
area, social background or economic issues. And they flatter us: Each potential
voter is made to feel like an indispensable member of the team: ‘Your vote
counts!’ Of course your vote counts, but only by the tiniest of fractions, bordering
on the irrelevant.</p>
<p>A friend who deals in oil pumps told me how he once closed an eight-figure
deal for a pipeline in Russia. ‘Bribery?’ I inquired. He shook his head. ‘We were
chatting, and suddenly we got on to the topic of sailing. It turned out that both of
us – the buyer and me – were die-hard 470 dinghy fans. From that moment on, he
liked me; I was a friend. So the deal was sealed. Amiability works better than
bribery.’</p>
<p>So, if you are a salesperson, make buyers think you like them, even if this means outright flattery. And if you are a consumer, always judge a product independent of who is selling it. Banish the salespeople from your mind, or rather, pretend you don’t like them.</p>
<h2 id="${'23-dont-cling-to-things'}"><a href="${'#23-dont-cling-to-things'}">23. DON’T CLING TO THINGS</a></h2>
<p>Endowment Effect</p>
<p>The BMW gleamed in the parking lot of the used-car dealership. Although it had a
few miles on the odometer, it looked in perfect condition. I know a little about used
cars, and to me it was worth around $40,000. However, the salesman was
pushing for $50,000 and wouldn’t budge a dime. When he called the next week to
say he would accept $40,000 after all, I went for it. The next day, I took it out for a
spin and stopped at a gas station. The owner came out to admire the car – and
proceeded to offer me $53,000 in cash on the spot. I politely declined. Only on the
way home did I realise how ridiculous I was to have said no. Something that I
considered worth $40,000 had passed into my possession and suddenly taken
on a value of more than $53,000. If I were thinking purely rationally, I would have
sold the car immediately. But, alas, I’d fallen under the influence of the
endowment effect. We consider things to be more valuable the moment we own
them. In other words, if we are selling something, we charge more for it than what
we ourselves would be willing to spend.</p>
<p>To probe this, psychologist Dan Ariely conducted the following experiment: in
one of his classes, he raffled tickets to a major basketball game, then polled the
students to see how much they thought the tickets were worth. The empty-handed
students estimated around $170, whereas the winning students would not sell
their ticket below an average of $2,400. The simple fact of ownership makes us
add zeros to the selling price.</p>
<p>In real estate, the endowment effect is palpable. Sellers become emotionally
attached to their houses and thus systematically overestimate their value. They
balk at the market price, expecting buyers to pay more – which is completely
absurd since this excess is little more than sentimental value.</p>
<p>We can safely say that we are better at collecting things than at casting them
off. Not only does this explain why we fill our homes with junk, but also why
lovers of stamps, watches and pieces of art part with them so seldomly.
Amazingly, the endowment effect affects not only possession but also nearownership.</p>
<p>Auction houses like Christie’s and Sotheby’s thrive on this. A person who bids until the end of an auction gets the feeling that the object is practically
theirs, thus increasing its value. The would-be owner is suddenly willing to pay
much more than planned, and any withdrawal from the bidding is perceived as a
loss – which defies all logic. In large auctions, such as those for mining rights or
mobile radio frequencies, we often observe the winner’s curse: here, the
successful bidder turns out to be the economic loser when he gets caught up in the fervour and overbids.</p>
<p>There’s a similar effect in the job market. If you are applying for a job and don’t
get a call back, you have every reason to be disappointed. However, if you make
it to the final stages of the selection process and then receive the rejection, the
disappointment can be much bigger – irrationally. Either you get the job or you
don’t; nothing else should matter.</p>
<p>In conclusion: don’t cling to things. Consider your property something that the
‘universe’ (whatever you believe this to be) has bestowed on you temporarily. Keep in mind that it can recoup this (or more) in the blink of an eye.</p>
<h2 id="${'24-the-inevitability-of-unlikely-events-coincidence'}"><a href="${'#24-the-inevitability-of-unlikely-events-coincidence'}">24. THE INEVITABILITY OF UNLIKELY EVENTS: Coincidence</a></h2>
<p>At 7.15p.m. on 1 March 1950, the fifteen members of the church choir in Beatrice,
Nebraska were scheduled to meet for rehearsal. For various reasons, they were
all running behind. The minister’s family was delayed because his wife still had to
iron their daughter’s dress. One couple was held back when their car wouldn’t
start. The pianist wanted to be there 30 minutes early, but he fell into a deep
sleep after dinner. And so on. At 7.25p.m., the church exploded. The blast was
heard all around the village. It blew out the walls and sent the roof crashing to the
ground. Miraculously, nobody was killed. The fire chief traced the explosion back
to a gas leak, even though members of the choir were convinced they had
received a sign from God. Hand of God or coincidence?</p>
<p>Something last week made me think of my old school friend, Andy, whom I
hadn’t spoken to in a long time. Suddenly the phone rang. I picked it up and, lo
and behold, it was Andy. ‘I must be telepathic!’ I exclaimed excitedly. But,
telepathy or coincidence?</p>
<p>On 5 October 1990, the San Francisco Examiner reported that Intel would take
its rival, AMD, to court. Intel found out that the company was planning to launch a
computer chip named AM386, a term which clearly referred to Intel’s 386 chip.
How Intel came upon the information is remarkable: by pure coincidence, both
companies had hired someone named Mike Webb. Both men were staying in the
same hotel in California, and checked out on the same day. After they had left, the
hotel accepted a package for Mike Webb at reception. It contained confidential
documents about the AM386 chip, and the hotel mistakenly sent it to Mike Webb
of Intel, who promptly forwarded the contents to the legal department.
How likely are stories like that? The Swiss psychiatrist C.G. Jung saw in them
the work of an unknown force, which he called synchronicity. But how should a
rationally minded thinker approach these accounts? Preferably with a piece of
paper and a pencil. Consider the first case, the explosion of the church. Draw four
boxes to represent each of the potential events. The first possibility is what
actually took place: ‘choir delayed and church exploded.’ But there are three
other options: ‘choir delayed and church did not explode,’ ‘choir on time and
church exploded’ and ‘choir on time and church did not explode.’ Estimate the
frequencies of these events and write them in the corresponding box. Pay special
attention to how often the last case has happened: every day, millions of choirs
gather for scheduled rehearsals and their churches don’t blow up. Suddenly, the
story has lost its unimaginable quality. For all these millions of churches, it would
be improbable if something like what happened in Beatrice, Nebraska didn’t take
place at least once a century. So, no: no hand of God. (And anyway, why would
God want to blow a church to smithereens? What a ridiculous way to
communicate with your worshippers!)</p>
<p>Let’s apply the same thinking to the phone call. Keep in mind the many
occasions when ‘Andy’ thinks of you but doesn’t call; when you think of him and
he doesn’t call; when you don’t think of him and he calls; when he doesn’t think of
you and you call?…?There is an almost infinite number of occasions when you
don’t think of him and he doesn’t call. But, since people spend about 90% of their
time thinking about others, it is not unlikely that, eventually, two people will think
of each other and one of them will pick up the phone. And it must not be just
Andy: if you have 100 other friends, the probability of this happening increases
greatly.</p>
<p>We tend to stumble when estimating probabilities. If someone says ‘never’, I
usually register this as a minuscule probability greater than zero, since ‘never’
cannot be compensated by a negative probability.</p>
<p>In sum: let’s not get too excited. Improbable coincidences are precisely that:
rare but very possible events. It’s not surprising when they finally happen. What
would be more surprising would be if they never came to be.</p>
<h2 id="${'25-the-calamity-of-conformity'}"><a href="${'#25-the-calamity-of-conformity'}">25. THE CALAMITY OF CONFORMITY</a></h2>
<p>Groupthink</p>
<p>Have you ever bitten your tongue in a meeting? Surely. You sit there, say nothing
and nod along to proposals. After all, you don’t want to be the (eternal) naysayer.
Moreover, you might not be 100% sure why you disagree, whereas the others are
unanimous – and far from stupid. So you keep your mouth shut for another day.
When everyone thinks and acts like this, groupthink is at work: this is where a
group of smart people makes reckless decisions because everyone aligns their
opinions with the supposed consensus. Thus, motions are passed that each
individual group member would have rejected if no peer pressure had been
involved. Groupthink is a special branch of social proof, a flaw that we discussed
in chapter 4.
In March 1960, the U.S. Secret Service began to mobilise anti-communist
exiles from Cuba, most of them living in Miami, to use against Fidel Castro’s
regime. In January 1961, two days after taking office, President Kennedy was
informed about the secret plan to invade Cuba. Three months later, a key meeting
took place at the White House in which Kennedy and his advisers all voted in
favour of the invasion. On 17 April 1961, a brigade of 1,400 exiled Cubans landed
at the Bay of Pigs, on Cuba’s south coast, with the help of the U.S. Navy, the Air
Force and the CIA. The aim was to overthrow Castro’s government. However,
nothing went as planned. On the first day, not a single supply ship reached the
coast. The Cuban air force sank the first two and the next two turned around and
fled back to the U.S. A day later, Castro’s army completely surrounded the
brigade. On the third day, the 1,200 survivors were taken into custody and sent to
military prisons. Kennedy’s invasion of the Bay of Pigs is regarded as one of the
biggest flops in American foreign policy. That such an absurd plan was ever
agreed upon, never mind put into action, is astounding. All of the assumptions
that spoke in favour of invasion were erroneous. For example, Kennedy’s team
completely underestimated the strength of Cuba’s air force. Also, it was expected
that, in an emergency, the brigade would be able to hide in the Escambray
mountains and carry out an underground war against Castro from there. A glance
at the map shows that the refuge was 100 miles away from the Bay of Pigs, with
an insurmountable swamp in between. And yet, Kennedy and his advisers were
among the most intelligent people to ever run an American government. What
went wrong between January and April of 1961?
Psychology professor Irving Janis has studied many fiascos. He concluded that
they share the following pattern: members of a close-knit group cultivate team
spirit by (unconsciously) building illusions. One of these fantasies is a belief in
invincibility: ‘If both our leader [in this case, Kennedy] and the group are confident
that the plan will work, then luck will be on our side.’ Next comes the illusion of
unanimity: if the others are of the same opinion, any dissenting view must be
wrong. No one wants to be the naysayer who destroys team unity. Finally, each
person is happy to be part of the group. Expressing reservations could mean
exclusion from it. In our evolutionary past, such banishment guaranteed death;
hence our strong urge to remain in the group’s favour.
The business world is no stranger to groupthink. A classic example is the fate
of the world-class airline Swissair. Here, a group of highly paid consultants rallied
around the former CEO and, bolstered by the euphoria of past successes,
developed a high-risk expansion strategy (including the acquisition of several
European airlines). The zealous team built up such a strong consensus that even
rational reservations were suppressed, leading to the airline’s collapse in 2001.
If you ever find yourself in a tight, unanimous group, you must speak your mind,
even if your team does not like it. Question tacit assumptions, even if you risk
expulsion from the warm nest. And, if you lead a group, appoint someone as
devil’s advocate. She will not be the most popular member of the team, but she
might be the most important.</p>
<h2 id="${'26-why-youll-soon-be-playing-megatrillions'}"><a href="${'#26-why-youll-soon-be-playing-megatrillions'}">26. WHY YOU’LL SOON BE PLAYING MEGATRILLIONS</a></h2>
<p>Neglect of Probability
Two games of chance: in the first, you can win $10 million, and in the second,
$10,000. Which do you play? If you win the first game, it changes your life
completely: you can quit your job, tell your boss where to go and live off the
winnings. If you hit the jackpot in the second game, you can take a nice vacation
in the Caribbean, but you’ll be back at your desk quick enough to see your
postcard arrive. The probability of winning is one in 100 million in the first game,
and one in 10,000 in the second game. So which do you choose?</p>
<p>Our emotions draw us to the first game, even though the second is ten times
better, objectively considered (expected win times probability). Therefore, the
trend is towards ever-larger jackpots – Mega Millions, Mega Billions, Mega
Trillions – no matter how small the odds are.</p>
<p>In a classic experiment from 1972, participants were divided into two groups.
The members of the first group were told that they would receive a small electric
shock. In the second group, subjects were told that the risk of this happening was
only 50%. The researchers measured physical anxiety (heart rate, nervousness,
sweating, etc.) shortly before commencing. The result were, well, shocking: there
was absolutely no difference. Participants in both groups were equally stressed.
Next, the researchers announced a series of reductions in the probability of a
shock for the second group: from 50% to 20%, then 10%, then 5%. The result: still
no difference! However, when they declared they would increase the strength of
the expected current, both groups’ anxiety levels rose – again, by the same
degree. This illustrates that we respond to the expected magnitude of an event
(the size of the jackpot or the amount of electricity), but not to its likelihood. In
other words: we lack an intuitive grasp of probability.</p>
<p>The proper term for this is neglect of probability, and it leads to errors in
decision-making. We invest in start-ups because the potential profit makes dollar
signs flash before our eyes, but we forget (or are too lazy) to investigate the slim
chances of new businesses actually achieving such growth. Similarly, following
extensive media coverage of a plane crash, we cancel flights without really
considering the minuscule probability of crashing (which, of course, remains the
same before and after such a disaster). Many amateur investors compare their
investments solely on the basis of yield. For them, Google shares with a return of
20% must be twice as good as property that returns 10%. That’s wrong. It would
be a lot smarter to also consider both investments’ risks. But then again, we have
no natural feel for this so we often turn a blind eye to it.</p>
<p>Back to the experiment with the electric shocks: in group B, the probability of
getting a jolt was further reduced: from 5% to 4% to 3%. Only when the probability
reached zero did group B respond differently to group A. To us, 0% risk seems
infinitely better than a (highly improbable) 1% risk.
To test this, let’s examine two methods of treating drinking water. Suppose a
river has two equally large tributaries. One is treated using method A, which
reduces the risk of dying from contaminated water from 5% to 2%. The other is
treated using method B, which reduces the risk from 1% to 0%, i.e. the threat is
completely eliminated. So, method A or B? If you think like most people, you will
opt for method B – which is silly because with measure A, 3% fewer people die,
and with B, just 1% fewer. Method A is three times as good! This fallacy is called
the zero-risk bias.
A classic example of this is the U.S. Food Act of 1958, which prohibits food that
contains cancer-causing substances. Instituted to achieve zero risk of cancer, this
ban sounds good at first, but it ended up leading to the use of more dangerous
(but non-carcinogenic) food additives. It is also absurd: as Paracelsus illustrated
in the sixteenth century, poisoning is always a question of dosage. Furthermore,
this law can never be enforced properly since it is impossible to remove the last
‘banned’ molecule from food. Each farm would have to function like a hypersterile computer-chip factory, and the cost of food would increase a hundredfold.
Economically, zero risk rarely makes sense. One exception is when the
consequences are colossal, such as a deadly, highly contagious virus escaping
from a biotech laboratory.</p>
<p>We have no intuitive grasp of risk and thus distinguish poorly between different
threats. The more serious the threat and the more emotional the topic (such as
radioactivity), the less reassuring a reduction in risk seems to us. Two
researchers at the University of Chicago have shown that people are equally
afraid of a 99% chance as they are of a 1% chance of contamination by toxic
chemicals. An irrational response, but a common one.</p>
<h2 id="${'27-scarcity-error'}"><a href="${'#27-scarcity-error'}">27. Scarcity Error</a></h2>
<p>Coffee at a friend’s house. We sat trying to make conversation while her three
children grappled with one another on the floor. Suddenly I remembered that I
had brought some glass marbles with me – a whole bag full. I spilled them out on
the floor, in the hope that the little angels would play with them in peace. Far from
it: a heated argument ensued. I didn’t understand what was happening until I
looked more closely. Among the countless marbles there was just one blue one,
and the children scrambled for it. All the marbles were exactly the same size and
shiny and bright. But the blue one had an advantage over the others – it was one
of a kind. I had to laugh at how childish children are!</p>
<p>In August 2005, when I heard that Google would launch its own email service, I
was dead set on getting an account. (In the end I did.) At the time, new accounts
were very restricted and were given out only on invitation. This made me want
one even more. But why? Certainly not because I needed another email account
(back then, I already had four), nor because Gmail was better than the
competition, but simply because not everyone had access to it. Looking back, I
have to laugh at how childish adults are!</p>
<p>Rara sunt cara, said the Romans. Rare is valuable. In fact, the scarcity error is
as old as mankind. My friend with the three children is a part-time real-estate
agent. Whenever she has an interested buyer who cannot decide, she calls and
says ‘A doctor from London saw the plot of land yesterday. He liked it a lot. What
about you? Are you still interested?’ The doctor from London – sometimes it’s a
professor or a banker – is, of course, fictitious. The effect is very real, though: it
causes prospects to see the opportunity disappearing before their eyes, so they
act and close the deal. Why? This is the potential shortage of supply, yet again.
Objectively, this situation is incomprehensible: either the prospect wants the land
for the set price or he does not – regardless of any doctors from London.
To assess the quality of cookies, Professor Stephen Worchel split participants
into two groups. The first group received an entire box of cookies, and the second
group just two. In the end, the subjects with just two cookies rated the quality
much higher than the first group did. The experiment was repeated several times
and always showed the same result.
‘Only while stocks last,’ the adverts alert. ‘Today only,’ warn the posters.
Gallery owners take advantage of the scarcity error by placing red ‘sold’ dots
under most of their paintings, transforming the remaining few works into rare
items that must be snatched up quickly. We collect stamps, coins, vintage cars
even when they serve no practical purpose. The post office doesn’t accept the old
stamps, the banks don’t take old coins, and the vintage cars are no longer
allowed on the road. These are all side issues; the attraction is that they are in
short supply.</p>
<p>In one study, students were asked to arrange ten posters in order of
attractiveness – with the agreement that afterward they could keep one poster as
a reward for their participation. Five minutes later, they were told that the poster
with the third highest rating was no longer available. Then they were asked to
judge all ten from scratch. The poster that was no longer available was suddenly
classified as the most beautiful. In psychology, this phenomenon is called
reactance: when we are deprived of an option, we suddenly deem it more
attractive. It is a kind of act of defiance. It is also known as the Romeo and Juliet
effect: because the love between the tragic Shakespearean teenagers is
forbidden, it knows no bounds. This yearning does not necessarily have to be a
romantic one; in the U.S., student parties are often littered with desperately drunk
teenagers – just because it’s illegal to drink below the age of 21.</p>
<p>In conclusion: the typical response to scarcity is a lapse in clear thinking.
Assess products and services solely on the basis of their price and benefits. It
should be of no importance if an item is disappearing fast, nor if any doctors from
London take an interest.</p>
<h2 id="${'28-base-rate-neglect'}"><a href="${'#28-base-rate-neglect'}">28. Base-Rate Neglect</a></h2>
<p>Mark is a thin man from Germany with glasses who likes to listen to Mozart.
Which is more likely? That Mark is A) a truck driver or B) a professor of literature
in Frankfurt. Most will bet on B, which is wrong. Germany has 10,000 times more
truck drivers than Frankfurt has literature professors. Therefore, it is more likely
that Mark is a truck driver. So what just happened? The detailed description
enticed us to overlook the statistical reality. Scientists call this fallacy base-rate
neglect: a disregard of fundamental distribution levels. It is one of the most
common errors in reasoning. Virtually all journalists, economists and politicians
fall for it on a regular basis.</p>
<p>Here is a second example: a young man is stabbed and fatally injured. Which
of these is more likely? A) The attacker is a Russian immigrant and imports
combat knives illegally, or B) the attacker is a middle-class American. You know
the drill now: option B is much more likely because there are a million times more
middle-class Americans than there are Russian knife importers.</p>
<p>In medicine, base-rate neglect plays an important role. For example, migraines
can point (among others) to a viral infection or a brain tumour. However, viral
infections are much more common (in other words, they have a higher base rate),
so doctors assess patients for these first before testing for tumours. This is very
reasonable. In medical school, residents spend a lot of time purging base-rate
neglect. The motto drummed into any prospective doctor in the United States is:
‘When you hear hoofbeats behind you, don’t expect to see a zebra.’ Which
means: investigate the most likely ailments before you start diagnosing exotic
diseases, even if you are a specialist in that.</p>
<p>Doctors are the only professionals who enjoy this base-rate training.
Regrettably, few people in business are exposed to it. Now and then I see highflying entrepreneurs’ business plans and get very excited by their products, ideas
and personalities. I often catch myself thinking: this could be the next Google! But
a glance at the base rate brings me back down to earth. The probability that a firm
will survive the first five years is 20%. So what then is the probability that they will
grow into a global corporation? Almost zero. Warren Buffett once explained why
he does not invest in biotech companies: ‘How many of these companies make a
turnover of several hundred million dollars? It simply does not happen?…?The
most likely scenario is that these firms will just hover somewhere in the middle.’
This is clear base-rate thinking. For most people, survivorship bias (chapter 1) is
one of the causes for their base-rate neglect. They tend to see only the successful
individuals and companies, because the unsuccessful cases are not reported (or
are under-reported). This makes them neglect the large part of the ‘invisible’
cases.</p>
<p>Imagine you are sampling wine in a restaurant and have to guess from which
country it comes. The label of the bottle is covered. If, like me, you are not a wine
connoisseur, the only lifeline you have is the base rate. You know from
experience that about three-quarters of the wines on the menu are of French
origin, so reasonably, you guess France, even if you suspect a Chilean or
Californian twist.</p>
<p>Sometimes I have the dubious honour of speaking in front of students of elite
business schools. When I ask them about their career prospects, most answer
that in the medium term, they see themselves on the boards of global companies.
Years ago, both my fellow students and I gave the same answer. The way I see it,
my role is to give students a base-rate crash course: ‘With a degree from this
school, the chance of you landing a spot on the board of a Fortune 500 company
is less than 0.1%. No matter how smart and ambitious you are, the most likely
scenario is that you will end up in middle management.’ With this, I earn shocked
looks, and tell myself that I have made a small contribution toward mitigating their
future mid-life crises.</p>
<h2 id="${'29-gamblers-fallacy'}"><a href="${'#29-gamblers-fallacy'}">29. Gambler’s Fallacy</a></h2>
<p>In the summer of 1913, something incredible happened in Monte Carlo. Crowds
gathered around a roulette table and could not believe their eyes. The ball had
landed on black twenty times in a row. Many players took advantage of the
opportunity and immediately put their money on red. But the ball continued to
come to rest on black. Even more people flocked to the table to bet on red. It had
to change eventually! But it was black yet again – and again and again. It was not
until the twenty-seventh spin that the ball eventually landed on red. By that time,
the players had bet millions on the table. In a few spins of the wheel, they were
bankrupt.</p>
<p>The average IQ of pupils in a big city is 100. To investigate this, you take a
random sample of 50 students. The first child tested has an IQ of 150. What will
the average IQ of your 50 students be? Most people guess 100. Somehow, they
think that the super-smart student will be balanced out – perhaps by a dismal
student with an IQ of 50 or by two below-average students with IQs of 75. But with
such a small sample, that is very unlikely. We must expect that the remaining 49
students will represent the average of the population, so they will each have an
average IQ of 100. Forty-nine times 100 plus one IQ of 150 gives us an average
of 101 in the sample.</p>
<p>The Monte Carlo example and the IQ experiment show that people believe in
the ‘balancing force of the universe’. This is the gambler’s fallacy. However, with
independent events, there is no harmonising force at work: a ball cannot
remember how many times it has landed on black. Despite this, one of my friends
enters the weekly Mega Millions numbers into a spreadsheet, and then plays
those that have appeared the least. All this work is for naught. He is another
victim of the gambler’s fallacy.</p>
<p>The following joke illustrates this phenomenon: a mathematician is afraid of
flying due to the small risk of a terrorist attack. So, on every flight he takes a bomb
with him in his hand luggage. ‘The probability of having a bomb on the plane is
very low,’ he reasons, ‘and the probability of having two bombs on the same
plane is virtually zero!’</p>
<p>A coin is flipped three times and lands on heads on each occasion. Suppose
someone forces you to spend thousands of dollars of your own money betting on
the next toss. Would you bet on heads or tails? If you think like most people, you
will choose tails, although heads is just as likely. The gambler’s fallacy leads us
to believe that something must change. </p>
<p>A coin is tossed 50 times, and each time it lands on heads. Again, with
someone forcing you to bet, do you pick heads or tails? Now that you’ve seen an
example or two, you’re wise to the game: you know that it could go either way.</p>
<p>But we’ve just come across another pitfall: the classic déformation
professionnelle (professional oversight) of mathematicians: common sense would
tell you that heads is the wiser choice, since the coin is obviously loaded.
Previously, we looked at regression to mean. An example: if you are
experiencing record cold where you live, it is likely that the temperature will return
to normal values over the next few days. If the weather functioned like a casino,
there would be a 50% chance that the temperature would rise and a 50% chance
that it would drop. But the weather is not like a casino. Complex feedback
mechanisms in the atmosphere ensure that extremes balance themselves out. In
other cases, however, extremes intensify. For example, the rich tend to get richer.
A stock that shoots up creates its own demand to a certain extent, simply because
it stands out so much – a sort of reverse compensation effect.</p>
<p>So, take a closer look at the independent and interdependent events around
you. Purely independent events really only exist at the casino, in the lottery and in
theory. In real life, in the financial markets and in business, with the weather and
your health, events are often interrelated. What has already happened has an
influence on what will happen. As comforting an idea as it is, there is simply no
balancing force out there for independent events. ‘What goes around, comes
around’ simply does not exist.</p>
<h2 id="${'30-the-anchor'}"><a href="${'#30-the-anchor'}">30 The Anchor</a></h2>
<p>When was Abraham Lincoln born? If you don’t know the year off the top of your
head, and your smartphone battery has just died, how do you answer this?
Perhaps you know that he was president during the Civil War in the 1860s and
that he was the first U.S. president to be assassinated. Looking at the Lincoln
Memorial in Washington, you don’t see a young, energetic man but something
more akin to a worn-out 60-year-old veteran. The memorial must depict him at the
height of his political power, say at the age of 60. Let’s assume that he was
assassinated in the mid-1860s, making 1805 our estimate for the year he was
born. (The correct answer is 1809.) So how did we work it out? We found an
anchor to help us – the 1860s – and worked from there to an educated guess.
Whenever we have to guess something – the length of the Mississippi River,
population density in Russia, the number of nuclear power plants in France – we
use anchors. We start with something we are sure of and venture into unfamiliar
territory from there. How else could we do it? Just pick a number off the top of our
heads? That would be irrational.</p>
<p>Unfortunately, we also use anchors when we don’t need to. For example, one
day in a lecture, a professor placed a bottle of wine on the table. He asked his
students to write down the last two digits of their social security numbers and then
decide if they would be willing to spend that amount on the wine. In the auction
that followed, students with higher numbers bid nearly twice as much as students
with lower numbers. The social security digits worked as an anchor – albeit in a
hidden and misleading way.</p>
<p>The psychologist Amos Tversky conducted an experiment involving a wheel of
fortune. He had participants spin it, and afterward, they were asked how many
member states the United Nations has. Their guesses confirmed the anchor
effect: the highest estimates came from people who had spun high numbers on
the wheel.
Researchers Russo and Shoemaker asked students in what year Attila the Hun
suffered his crushing defeat in Europe. Just like the example with social security
numbers, the participants were anchored – this time with the last few digits of their
telephone number. The result? People with higher numbers chose later years
and vice versa. (If you were wondering, Attila’s demise came about in 453.)
Another experiment: students and professional real-estate agents were given a
tour of a house and asked to estimate its value. Beforehand, they were informed
about a (randomly generated) listed sales price. As might be expected, the
anchor influenced the students: the higher this price, the higher they valued the
property. And the professionals? Did they value the house objectively? No, they
were similarly influenced by the random anchor amount. The more uncertain the
value of something – such as real estate, company stock or art – the more
susceptible even experts are to anchors.
Anchors abound, and we all clutch at them. The ‘recommended retail price’
printed on many products is nothing more than an anchor. Sales professionals
know they must establish a price at an early stage – long before they have an
offer. Also, it has been proven that if teachers know students’ past grades, it
influences how they will mark new work. The most recent grades act as a starting
point.
In my early years, I had a quick stint at a consulting firm. My boss was a pro
when it came to using anchors. In his first conversation with any client, he made
sure to fix an opening price, which, by the way, almost criminally exceeded our
internal costs: ‘I’ll tell you this now so you’re not surprised when you receive the
quote, Mr. So-and-So: we’ve just completed a similar project for one of your
competitors and it was in the range of five million dollars.’ The anchor was
dropped: the price negotiations started at exactly five million</p>`;
});
export { The_art_of_thinking_clearly as default, metadata };
